{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "609c349e",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b42d6eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a89225f",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ff9c63",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65f3aee8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths to images\n",
    "image_path_arnau = \"data/Arnau\"\n",
    "image_path_ashley = \"data/Ashley\"\n",
    "\n",
    "# Prepare list with image paths\n",
    "file_list_arnau = os.listdir(image_path_arnau)\n",
    "file_list_arnau = [ f for f in file_list_arnau if f.endswith('.jpeg') or f.endswith('.jpg')]\n",
    "file_list_ashley = os.listdir(image_path_ashley)\n",
    "file_list_ashley = [ f for f in file_list_ashley if f.endswith('.jpeg') or f.endswith('.jpg')]\n",
    "\n",
    "# Join lists and create labels\n",
    "file_list = file_list_arnau + file_list_ashley\n",
    "labels = np.array([0] * len(file_list_arnau) + [1] * len(file_list_ashley))\n",
    "\n",
    "# Check that file_list and labels have the same shape\n",
    "len(file_list) == len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1e625d",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082aa1f5",
   "metadata": {},
   "source": [
    "### Functions for face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f8893d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find center of boundary box and return it.\n",
    "def findCenterBbox(bbox):\n",
    "    x_min, y_min, w, h = bbox\n",
    "    x_max = x_min + w\n",
    "    y_max = y_min + h\n",
    "\n",
    "    center = [int((x_max + x_min)//2), int((y_max + y_min)//2)] \n",
    "\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4415247a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find face using the OpenCV library and return boundary box.\n",
    "def findFaces(img):\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faceDetection = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    results = faceDetection.detectMultiScale(imgGray, 1.1, 10, minSize=[int(0.25*imgGray.shape[0]),int(0.25*imgGray.shape[1])])\n",
    "\n",
    "    bboxs = []\n",
    "    \n",
    "    if len(results):\n",
    "        counter = 1\n",
    "        for bbox in results:\n",
    "            center_bbox = findCenterBbox(bbox)\n",
    "            bboxs.append([counter, bbox, center_bbox])\n",
    "            counter = counter + 1\n",
    "\n",
    "    return bboxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9779fc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dimensions of a square box based on the center and the dimensions.\n",
    "def makeSquareCrop(x_min, y_min, w, h):\n",
    "    centerX = x_min + round(w/2)\n",
    "    centerY = y_min + round(h/2)\n",
    "    dim = max([w,h])\n",
    "\n",
    "    x_min = centerX - round(dim/2)\n",
    "    y_min = centerY - round(dim/2)\n",
    "\n",
    "    w = dim\n",
    "    h = dim\n",
    "\n",
    "    return x_min, y_min, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf5ca83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the boundaries are valid.\n",
    "def boundariesValidation(x, y):\n",
    "    x = max([x, 0])\n",
    "    y = max([y, 0])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69653bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop image and return it.\n",
    "def crop(img, bbox):\n",
    "    x_min, y_min, w, h = bbox\n",
    "\n",
    "    x_min, y_min, w, h = makeSquareCrop(x_min, y_min, w, h)        \n",
    "\n",
    "    x_min, y_min = boundariesValidation(x_min, y_min)\n",
    "\n",
    "    return img[y_min:y_min+h, x_min:x_min+w]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c83da9",
   "metadata": {},
   "source": [
    "### Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7236bb52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|███████████████████████████████████████████████████████████████████▊                                                  | 666/1159 [00:39<00:09, 50.09it/s]libpng warning: iCCP: known incorrect sRGB profile\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1159/1159 [00:50<00:00, 23.05it/s]\n"
     ]
    }
   ],
   "source": [
    "input_size = [32,32] # Input size of image\n",
    "\n",
    "# Initialize img_feature to store the images\n",
    "img_features = np.empty([1,input_size[0], input_size[1],3])\n",
    "idx_keep = []\n",
    "\n",
    "# For loop to iterate through all files\n",
    "for i in tqdm(range(1,len(file_list))):\n",
    "\n",
    "    f = file_list[i] # Current file\n",
    "    \n",
    "    # Path based on label\n",
    "    if labels[i]:\n",
    "        path = image_path_ashley + '/' + f\n",
    "    else:\n",
    "        path = image_path_arnau + '/' + f\n",
    "\n",
    "    # Skip iteration if image cannot be loaded\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    bboxs = findFaces(img) # Find face\n",
    "\n",
    "    # If no faces have been found, skip face\n",
    "    if(len(bboxs) == 0):\n",
    "        continue     \n",
    "    \n",
    "    # Crop faces in square dimensions\n",
    "    img_face = crop(img, bboxs[0][1])\n",
    "    \n",
    "    # Resize image into input_size and convert BGR to RGB\n",
    "    img_face_ds = cv2.resize(img_face, (input_size[0],input_size[1]))\n",
    "    img_face_ds = cv2.cvtColor(img_face_ds, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Reshape image and append it to img_features\n",
    "    features = np.reshape(img_face_ds,[1,input_size[0],input_size[1],3])\n",
    "    img_features = np.append(img_features,features,axis=0)\n",
    "\n",
    "    idx_keep.append(i) # Indices of images with detected faces\n",
    "\n",
    "# Delete positions where no faces have been detected\n",
    "img_features = np.delete(img_features,obj=0,axis=0)\n",
    "labels = labels[idx_keep]\n",
    "\n",
    "N_samples = img_features.shape[0] # Compute number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88d5c581",
   "metadata": {},
   "source": [
    "# Deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac67270",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN) architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1dfde68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 12:21:18.333367: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2022-02-23 12:21:18.334604: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Conv2D(input_size[0], (3, 3), activation='relu', input_shape=(input_size[0], input_size[1], 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092e0b7c",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeee75d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 12:21:18.627353: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2022-02-23 12:21:18.885256: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 1s 28ms/step - loss: 3.8846 - accuracy: 0.6962 - val_loss: 0.9835 - val_accuracy: 0.6948\n",
      "Epoch 2/10\n",
      "14/16 [=========================>....] - ETA: 0s - loss: 0.5388 - accuracy: 0.7991"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 12:21:19.504025: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16/16 [==============================] - 0s 11ms/step - loss: 0.5118 - accuracy: 0.8089 - val_loss: 0.3079 - val_accuracy: 0.8826\n",
      "Epoch 3/10\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.3494 - accuracy: 0.8632 - val_loss: 0.1613 - val_accuracy: 0.9437\n",
      "Epoch 4/10\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1536 - accuracy: 0.9557 - val_loss: 0.2037 - val_accuracy: 0.9061\n",
      "Epoch 5/10\n",
      "16/16 [==============================] - 0s 11ms/step - loss: 0.1828 - accuracy: 0.9276 - val_loss: 0.2057 - val_accuracy: 0.9249\n",
      "Epoch 6/10\n",
      "16/16 [==============================] - 0s 15ms/step - loss: 0.1690 - accuracy: 0.9256 - val_loss: 0.1504 - val_accuracy: 0.9531\n",
      "Epoch 7/10\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0468 - accuracy: 0.9819 - val_loss: 0.1027 - val_accuracy: 0.9718\n",
      "Epoch 8/10\n",
      "16/16 [==============================] - 0s 13ms/step - loss: 0.0281 - accuracy: 0.9899 - val_loss: 0.0836 - val_accuracy: 0.9765\n",
      "Epoch 9/10\n",
      "16/16 [==============================] - 0s 14ms/step - loss: 0.0275 - accuracy: 0.9960 - val_loss: 0.1249 - val_accuracy: 0.9765\n",
      "Epoch 10/10\n",
      "16/16 [==============================] - 0s 12ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0964 - val_accuracy: 0.9765\n",
      "7/7 - 0s - loss: 0.0964 - accuracy: 0.9765 - 38ms/epoch - 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define indices of training (70%) and testing (30%)\n",
    "train_indices = random.sample(range(0, N_samples), round(N_samples*0.7)) #int(np.floor(img_features.shape[0]*0.7))\n",
    "test_indices = list(set(list(range(0,N_samples))).difference(set(train_indices)))\n",
    "\n",
    "# Split images into training and testing\n",
    "train = img_features[train_indices,:,:,:]\n",
    "train_labels = labels[train_indices]\n",
    "\n",
    "test = img_features[test_indices,:,:,:]\n",
    "test_labels = labels[test_indices]\n",
    "\n",
    "# Train CNN model\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train, train_labels, epochs=10, validation_data=(test, test_labels))\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "643db2c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 12:21:21.689165: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: data/my_model/assets\n"
     ]
    }
   ],
   "source": [
    "# Save model\n",
    "model.save('data/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fe8774e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free memory\n",
    "#del img_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46718057",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14f152de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-02-23 12:21:54.338258: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('data/my_model') # Import model\n",
    "cap = cv2.VideoCapture(0) # Load webcam\n",
    "class_names = ['Arnau', 'Ashley'] # Classes names\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# Real-time face recognition\n",
    "while for_loop:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, None, fx=0.5, fy=0.5,\n",
    "                       interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    bboxs = findFaces(frame)\n",
    "\n",
    "    c = cv2.waitKey(1)\n",
    "\n",
    "    if c == 27:  # Escape\n",
    "        break\n",
    "\n",
    "    for i in range(0, len(bboxs)):\n",
    "        bbox = bboxs[i][1]\n",
    "        img_face = crop(frame, bbox)\n",
    "        img_face_ds = cv2.resize(img_face, (input_size[0], input_size[1]))\n",
    "        img_face_ds = cv2.cvtColor(img_face_ds, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        predictions = model.predict(\n",
    "            np.reshape(img_face_ds, [1, img_face_ds.shape[0], img_face_ds.shape[1], 3]))\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "        pred_class = class_names[np.argmax(score)]\n",
    "        pred_score = 100 * np.max(score)\n",
    "        cv2.rectangle(\n",
    "            frame, (bbox[0], bbox[1]), (bbox[0]+bbox[2], bbox[1]+bbox[3]), (255, 0, 0), 2)\n",
    "        cv2.putText(\n",
    "            frame, pred_class + ' | ' + str(int(pred_score)) + '%', org=(bbox[0]+bbox[2], bbox[1]), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1, color=(255, 0, 0))\n",
    "\n",
    "    cv2.imshow('Input', frame)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
