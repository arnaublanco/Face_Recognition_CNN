{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "725459e2",
   "metadata": {},
   "source": [
    "# Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1b85aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import random\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1a9732",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf69384",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a0b1de3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Paths to images\n",
    "image_path_arnau = \"data/Arnau\"\n",
    "image_path_ashley = \"data/Ashley\"\n",
    "\n",
    "# Prepare list with image paths\n",
    "file_list_arnau = os.listdir(image_path_arnau)\n",
    "file_list_arnau = [ f for f in file_list_arnau if f.endswith('.jpeg') or f.endswith('.jpg')]\n",
    "file_list_ashley = os.listdir(image_path_ashley)\n",
    "file_list_ashley = [ f for f in file_list_ashley if f.endswith('.jpeg') or f.endswith('.jpg')]\n",
    "\n",
    "# Join lists and create labels\n",
    "file_list = file_list_arnau + file_list_ashley\n",
    "labels = np.array([0] * len(file_list_arnau) + [1] * len(file_list_ashley))\n",
    "\n",
    "# Check that file_list and labels have the same shape\n",
    "len(file_list) == len(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf85b29f",
   "metadata": {},
   "source": [
    "## Data import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8630bfdf",
   "metadata": {},
   "source": [
    "### Functions for face detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cde92e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find center of boundary box and return it.\n",
    "def findCenterBbox(bbox):\n",
    "    x_min, y_min, w, h = bbox\n",
    "    x_max = x_min + w\n",
    "    y_max = y_min + h\n",
    "\n",
    "    center = [int((x_max + x_min)//2), int((y_max + y_min)//2)] \n",
    "\n",
    "    return center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ea1c2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find face using the OpenCV library and return boundary box.\n",
    "def findFaces(img):\n",
    "    imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    faceDetection = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')\n",
    "    results = faceDetection.detectMultiScale(imgGray, 1.1, 10, minSize=[int(0.25*imgGray.shape[0]),int(0.25*imgGray.shape[1])])\n",
    "\n",
    "    bboxs = []\n",
    "    \n",
    "    if len(results):\n",
    "        counter = 1\n",
    "        for bbox in results:\n",
    "            center_bbox = findCenterBbox(bbox)\n",
    "            bboxs.append([counter, bbox, center_bbox])\n",
    "            counter = counter + 1\n",
    "\n",
    "    return bboxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cc9d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the dimensions of a square box based on the center and the dimensions.\n",
    "def makeSquareCrop(x_min, y_min, w, h):\n",
    "    centerX = x_min + round(w/2)\n",
    "    centerY = y_min + round(h/2)\n",
    "    dim = max([w,h])\n",
    "\n",
    "    x_min = centerX - round(dim/2)\n",
    "    y_min = centerY - round(dim/2)\n",
    "\n",
    "    w = dim\n",
    "    h = dim\n",
    "\n",
    "    return x_min, y_min, w, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a53f15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the boundaries are valid.\n",
    "def boundariesValidation(x, y):\n",
    "    x = max([x, 0])\n",
    "    y = max([y, 0])\n",
    "\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "84514922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop image and return it.\n",
    "def crop(img, bbox):\n",
    "    x_min, y_min, w, h = bbox\n",
    "\n",
    "    x_min, y_min, w, h = makeSquareCrop(x_min, y_min, w, h)        \n",
    "\n",
    "    x_min, y_min = boundariesValidation(x_min, y_min)\n",
    "\n",
    "    return img[y_min:y_min+h, x_min:x_min+w]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ccb116a",
   "metadata": {},
   "source": [
    "### Data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014e710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|██████████████████████████████████████████████▍                                                                       | 456/1159 [00:33<00:52, 13.34it/s]"
     ]
    }
   ],
   "source": [
    "input_size = [32,32] # Input size of image\n",
    "\n",
    "# Initialize img_feature to store the images\n",
    "img_features = np.empty([1,input_size[0], input_size[1],3])\n",
    "idx_keep = []\n",
    "\n",
    "# For loop to iterate through all files\n",
    "for i in tqdm(range(1,len(file_list))):\n",
    "\n",
    "    f = file_list[i] # Current file\n",
    "    \n",
    "    # Path based on label\n",
    "    if labels[i]:\n",
    "        path = image_path_ashley + '/' + f\n",
    "    else:\n",
    "        path = image_path_arnau + '/' + f\n",
    "\n",
    "    # Skip iteration if image cannot be loaded\n",
    "    img = cv2.imread(path)\n",
    "    if img is None:\n",
    "        continue\n",
    "    \n",
    "    bboxs = findFaces(img) # Find face\n",
    "\n",
    "    # If no faces have been found, skip face\n",
    "    if(len(bboxs) == 0):\n",
    "        continue     \n",
    "    \n",
    "    # Crop faces in square dimensions\n",
    "    img_face = crop(img, bboxs[0][1])\n",
    "    \n",
    "    # Resize image into input_size and convert BGR to RGB\n",
    "    img_face_ds = cv2.resize(img_face, (input_size[0],input_size[1]))\n",
    "    img_face_ds = cv2.cvtColor(img_face_ds, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Reshape image and append it to img_features\n",
    "    features = np.reshape(img_face_ds,[1,input_size[0],input_size[1],3])\n",
    "    img_features = np.append(img_features,features,axis=0)\n",
    "\n",
    "    idx_keep.append(i) # Indices of images with detected faces\n",
    "\n",
    "# Delete positions where no faces have been detected\n",
    "img_features = np.delete(img_features,obj=0,axis=0)\n",
    "labels = labels[idx_keep]\n",
    "\n",
    "N_samples = img_features.shape[0] # Compute number of samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b0b5d4",
   "metadata": {},
   "source": [
    "# Deep learning model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb81e4ed",
   "metadata": {},
   "source": [
    "## Convolutional Neural Network (CNN) architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c358bea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential(\n",
    "    [\n",
    "    tf.keras.layers.Conv2D(input_size[0], (3, 3), activation='relu', input_shape=(input_size[0], input_size[1], 3)),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "\n",
    "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
    "    tf.keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38f39d4c",
   "metadata": {},
   "source": [
    "## Model fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a862c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define indices of training (70%) and testing (30%)\n",
    "train_indices = random.sample(range(0, N_samples), round(N_samples*0.7)) #int(np.floor(img_features.shape[0]*0.7))\n",
    "test_indices = list(set(list(range(0,N_samples))).difference(set(train_indices)))\n",
    "\n",
    "# Split images into training and testing\n",
    "train = img_features[train_indices,:,:,:]\n",
    "train_labels = labels[train_indices]\n",
    "\n",
    "test = img_features[test_indices,:,:,:]\n",
    "test_labels = labels[test_indices]\n",
    "\n",
    "# Train CNN model\n",
    "model.compile(optimizer='adam', loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True), metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(train, train_labels, epochs=10, validation_data=(test, test_labels))\n",
    "\n",
    "plt.plot(history.history['accuracy'], label='accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.ylim([0, 1])\n",
    "plt.legend(loc='lower right')\n",
    "\n",
    "test_loss, test_acc = model.evaluate(test,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370c079b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model.save('data/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c2a48b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Free memory\n",
    "#del img_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "217d8de2",
   "metadata": {},
   "source": [
    "# Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba681ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model('data/my_model') # Import model\n",
    "cap = cv2.VideoCapture(0) # Load webcam\n",
    "class_names = ['Arnau', 'Ashley'] # Classes names\n",
    "\n",
    "# Check if the webcam is opened correctly\n",
    "if not cap.isOpened():\n",
    "    raise IOError(\"Cannot open webcam\")\n",
    "\n",
    "# Real-time face recognition\n",
    "while for_loop:\n",
    "    ret, frame = cap.read()\n",
    "    frame = cv2.resize(frame, None, fx=0.5, fy=0.5,\n",
    "                       interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    bboxs = findFaces(frame)\n",
    "\n",
    "    c = cv2.waitKey(1)\n",
    "\n",
    "    if c == 27:  # Escape\n",
    "        cap.release()\n",
    "        break\n",
    "\n",
    "    for i in range(0, len(bboxs)):\n",
    "        bbox = bboxs[i][1]\n",
    "        img_face = crop(frame, bbox)\n",
    "        img_face_ds = cv2.resize(img_face, (input_size[0], input_size[1]))\n",
    "        img_face_ds = cv2.cvtColor(img_face_ds, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        predictions = model.predict(\n",
    "            np.reshape(img_face_ds, [1, img_face_ds.shape[0], img_face_ds.shape[1], 3]))\n",
    "        score = tf.nn.softmax(predictions[0])\n",
    "        pred_class = class_names[np.argmax(score)]\n",
    "        pred_score = 100 * np.max(score)\n",
    "        cv2.rectangle(\n",
    "            frame, (bbox[0], bbox[1]), (bbox[0]+bbox[2], bbox[1]+bbox[3]), (255, 0, 0), 2)\n",
    "        cv2.putText(\n",
    "            frame, pred_class + ' | ' + str(int(pred_score)) + '%', org=(bbox[0]+bbox[2], bbox[1]), fontFace=cv2.FONT_HERSHEY_PLAIN, fontScale=1, color=(255, 0, 0))\n",
    "\n",
    "    cv2.imshow('Input', frame)\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1) # Bug for MacOS (window does not close)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
